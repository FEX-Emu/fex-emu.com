---
layout: post
title: FEX 2209 Tagged!
author: FEX-Emu Maintainers
---

A lot of miscellaneous work this month that isn't directly user facing. We do still have some interesting topics this month that some people will be
interested in.

# Simplify StealMemory functions
A fairly significant change this month is reducing the time it takes FEX to set up its memory upon load. FEX needs to do an initial setup of the memory when an application loads
because between x86-64, x86, and AArch64 the memory layouts are significantly different.

Depending on the architecture of the application, FEX needs to allocate a large amount of memory to emulate the x86/x86-64 memory behaviour.

__On 32-bit x86__
* We need to allocate all memory above 32-bit memory space
  * This is because we emulate 32-bit applications as a 64-bit AArch64 application

__On 64-bit x86-64__
* We need to allocate all memory in the 48-bit virtual address space
  * This is because AArch64 supports the full 48-bit space for the user
  * x86-64 userspace only receives 47-bit
  * Application's rely on _not_ receiving 48-bit pointers!

<div id="Allocator_graph_raw" style="min-width: 250px; height: 300px; margin: 0 auto">
</div>

From this graph showing the amount of CPU time spent in each routine, we can see a significant reduction in time to execute.
For 32-bit and 64-bit specific operations this results in a __~70x__ and __~181x__ reduction in  in execution time!

How well does this improve execution time in practice though?

<div id="Allocator_graph" style="min-width: 250px; height: 300px; margin: 0 auto">
</div>

This graph is showing the total time it takes to run applications fully through. The smallest test applications have shaved off around __75% - 85%__ their execution time. The biggest improvement
comes from Proton setting up its execution environment. Proton's underlying execution environment is called _pressure-vessel_ which executes hundreds
of background applications while setting up. This is one of the worst cases for FEX since each independent application execution needs to JIT new code
and handle all of its state setup. This case reduces the execution time from around __21 seconds__ down to around __17 seconds__! This can _really_
be felt when execution back to back Proton instances when testing games!

While this is a significant step in the right direction, FEX still has a ways to go to hit the native execution time of pressure-vessel which can take
as little as one second.

# More AVX work
A bunch more work has gone in to supporting AVX emulation. This is still preliminary backend work for now.

- HostRunner
  - Handle upper YMM lanes in sigsegv handler

- InterpreterOps
  - Extend SSAData size to accomodate 256-bit operations

- VectorOps
  - Extend VAnd/VBic/VOr/VXor
  - Extend VMov
  - Extend VectorImm
  - Extend VectorZero

# Thunks
## X11
Some fairly minor changes here that improve usability of thunks with Proton. We added more Xlibint functions to the thunks which fixes X11 thunking
with DXVK. X11 is required for both Vulkan and OpenGL thunking so having this working is necessary when running those games.

Another necessary change for supporting thunks with Wine/Proton is more aggressively supporting X11 functions which require variadic arguments. There
are quite a few of these functions sprinkled around that require this. While we supported these functions with open-coded support up to 7 arguments,
we need to support at least up to 14 arbitrary arguments in some instances. We now have some assembly code in place which can support an arbitrary
number of arguments by packing these in memory the expected way. While this only works for 64-bit integers, it's all that we need for X11.

With both of these features implemented both OpenGL and Vulkan thunking works with Proton.

## VDSO
While this is implemented as a thunk on the FEX side, it behaves slightly differently that normal thunks. This will always be enabled as long as FEX
can load the VDSO-host.so library installed on the system. Due to the nature of VDSO, all applications always have a VDSO region provided by the
kernel at all times. FEX wants to provide fast emulation of this "library" since applications abuse it heavily for performance. This was noticed when
running Proton games, they abuse the clock_gettime very heavily which was causing significant CPU overhead. Applications were calling this VDSO
syscall hundreds or thousands of times a second. This now significantly lowers the amount of time spent in the kernel for timing functions.

# getdents syscall emulation
AArch64 doesn't support this syscall but in most cases applications don't use it. This is because there is a much more modern syscall called
getdents64 that everything uses now. When running older compiled applications they are likely to use the classic syscall. Since AArch64 doesn't have
the classic version, we now emulate it entirely using getdents64, which fixes running applications from centos 7.

## Misc
- Fix compiling without jemalloc
  - Thunks are unsupported without jemalloc but we need to keep it compiling
- Consolidate generated files to one file per platform
  - Nice code cleanup for developers
- Minor cleanups for signature-based function pointer thunking
- Support direct thunk config in configuration files
  - This improves the user experience with enabling thunks for application configurations
  - No need for two files to describe one thing now

See the [2209 Release Notes](https://github.com/FEX-Emu/FEX/releases/tag/FEX-2209) or the [detailed change log](https://github.com/FEX-Emu/FEX/compare/FEX-2208...FEX-2209) in Github.

<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.8.2/jquery.min.js">
</script>
<script src="https://code.highcharts.com/highcharts.js">
</script>
<script src="https://code.highcharts.com/modules/exporting.js">
</script>

<script type="text/javascript">
Highcharts.chart('Allocator_graph', {
    chart: {
        type: 'column'
    },
    title: {
        text: 'Time to execute'
    },
    xAxis: {
        categories: [
            'Proton setup',
            '64-bit \'true\' app',
            '32-bit \'true\' app'
        ],
        crosshair: true
    },
    yAxis: {
        type: 'logarithmic',
        title: {
            useHTML: true,
            text: 'Milliseconds'
        }
    },
    tooltip: {
        headerFormat: '<span style="font-size:10px">{point.key}</span><table>',
        pointFormat: '<tr><td style="color:{series.color};padding:0">{series.name}: </td>' +
            '<td style="padding:0"><b>{point.y:.1f}</b></td></tr>',
        footerFormat: '</table>',
        shared: true,
        useHTML: true
    },
    plotOptions: {
        column: {
            pointPadding: 0.2,
            borderWidth: 0
        }
    },
    series: [{
        name: 'Post-Optimization',
        data: [17195.4, 60, 82.8]

    }, {
        name: 'Pre-Optimization',
        data: [21448.5, 70, 109.2]
    }]
});
Highcharts.chart('Allocator_graph_raw', {
    chart: {
        type: 'column'
    },
    title: {
        text: 'Time to execute'
    },
    xAxis: {
        categories: [
            'Raw x86 function time',
            'Raw x86-64 function time'
        ],
        crosshair: true
    },
    yAxis: {
        type: 'logarithmic',
        title: {
            useHTML: true,
            text: 'Microseconds'
        }
    },
    tooltip: {
        headerFormat: '<span style="font-size:10px">{point.key}</span><table>',
        pointFormat: '<tr><td style="color:{series.color};padding:0">{series.name}: </td>' +
            '<td style="padding:0"><b>{point.y:.1f}</b></td></tr>',
        footerFormat: '</table>',
        shared: true,
        useHTML: true
    },
    plotOptions: {
        column: {
            pointPadding: 0.2,
            borderWidth: 0
        }
    },
    series: [{
        name: 'Post-Optimization',
        data: [456, 259]

    }, {
        name: 'Pre-Optimization',
        data: [83069, 18106]
    }]
});

</script>
